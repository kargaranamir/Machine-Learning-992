{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "id": "7P66a3NStetI",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# CE-40717: Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## HW4-MultiLayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ZsX3itNwTc8T"
   },
   "source": [
    "The following lines of code will load the [MNIST](http://yann.lecun.com/exdb/mnist/) data and turn them\n",
    "into numpy arrays, you can print their shape if you like.\n",
    "You can also transform the data as you wish, including seperating\n",
    "the training data for cross validation.\n",
    "\n",
    "If you have the data (on google drive or locally) change the root\n",
    "address accordingly, if you don't, set download=True but you might encounter\n",
    "some problems downloading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "eRDGolwttJJr"
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as ds\n",
    "import numpy as np\n",
    "\n",
    "data_train = np.array(ds.MNIST(root=\"./data\", train=True, download=True).data)\n",
    "target_train = np.array(ds.MNIST(root=\"./data\", train=True, download=True).targets)\n",
    "data_test = np.array(ds.MNIST(root=\"./data\", train=False, download=True).data)\n",
    "target_test = np.array(ds.MNIST(root=\"./data\", train=False, download=True).targets)\n",
    "\n",
    "#### Transform the data! ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "hidden": true,
    "id": "OQ0i1tVuT3bb",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Part1:\n",
    "Complete the functions of the MLP class to create\n",
    "a MultiLayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "86AdE8SntShx"
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, in_dimensions, hidden_dimensions, out_dimensions):\n",
    "        self.w1 = np.random.normal(size=(in_dimensions, hidden_dimensions)) / in_dimensions\n",
    "        self.b1 = np.random.normal(size=(1,hidden_dimensions)) / in_dimensions\n",
    "        self.w2 = np.random.normal(size=(hidden_dimensions,out_dimensions)) / in_dimensions\n",
    "        self.b2 = np.random.normal(size=(1,out_dimensions)) / in_dimensions\n",
    "\n",
    "    def forward(self, x):\n",
    "        # perform a forward pass of the network and return the result\n",
    "        # remember to retain the value of each node (i.e. self.h1_forward)\n",
    "        # in order to use in backpropagation\n",
    "        # Use whatever activation function you wish for the first layer\n",
    "        # and softmax activation for the output layer\n",
    "        pass\n",
    "\n",
    "    def backward(self, loss, y):\n",
    "        # perform backpropagation on the loss value and compute the gradient \n",
    "        # w.r.t. every element of the network and retain them (i.e. self.w1_backward)\n",
    "        pass\n",
    "\n",
    "    def step(self, lr, lam):\n",
    "        # simply update all the weights using the gradinets computed in backward\n",
    "        # and the given learning rate with SGD\n",
    "        # don't forget to use regularization\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "hidden": true,
    "id": "EeMLiOlMUC2D",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Part2:\n",
    "Make instances of your network and train them **using l2 regularization and choose the lambda using k-fold cross validation\n",
    "(set the candidate lambda as you wish)**.\n",
    "\n",
    "You may choose the hyperparameters (i.e. num of epochs, learning rate etc.)\n",
    "as you wish. \n",
    "\n",
    "Then train a final model on all the training data with the chosen lambda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "0Ojg9CSL4vei"
   },
   "outputs": [],
   "source": [
    "n_epochs = # number of epochs\n",
    "lr = # learning rate\n",
    "k = # number of folds\n",
    "in_dim = # MNIST has 28*28 images\n",
    "hidden_dim = # number of hidden dimensions for the hidden layer\n",
    "out_dim =  # MNIST has 10 classes\n",
    "fold_len = int(data_train.shape[0]/k)\n",
    "lambdas = [] \n",
    "best_lambda = lambdas[-1]\n",
    "best_acc = 0\n",
    "\n",
    "for l in lambdas:\n",
    "    model = MLP(in_dim, hidden_dim, out_dim)\n",
    "    acc = 0 # accuracy for current lambda\n",
    "    loss = 0 # loss for current lambda\n",
    "    for j in range(k):\n",
    "        fold_train_set = # the training data for the current fold\n",
    "        fold_train_target = # the training targets for the current fold\n",
    "        val_set = # the validation data for the current fold\n",
    "        val_target = # the validation targets for the current fold\n",
    "\n",
    "        for i in range(n_epochs):\n",
    "            # train the model on the data with the curent lambda\n",
    "\n",
    "        # test the model on the current validation data\n",
    "        fold_acc = # current fold accuracy\n",
    "        fold_loss = # current fold loss\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Lambda:\", l)\n",
    "    print(\"Loss: %.4f Accuracy: %.4f\" % (loss, acc))\n",
    "    print()\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_lambda = l\n",
    "\n",
    "print(\"Best lambda is\",best_lambda, \"with %.4f accuracy\" % best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "hidden": true,
    "id": "6cDg4S27xD5Y",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Part3:\n",
    "Train a final model using the best lambda on all the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "fE1mC1BkxMdt"
   },
   "outputs": [],
   "source": [
    "n_epochs = # number of epochs\n",
    "lr = # learning rate\n",
    "model = # new model\n",
    "for i in range(n_epochs):\n",
    "      #### training code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Part4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "6X8hFKXQUeml"
   },
   "source": [
    "Plot the training loss value and accuracy (mean over all batches each epoch if you're using mini-batches) over epochs\n",
    "for the final model that is trained on all the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "_LpeQU225eGi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "WIaBwatyUqmC"
   },
   "source": [
    "Use your network on the test set and report the accuracy, you must get at least 70% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "NmQiBh4C5ULJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "zyp8Wgx_nV-A"
   },
   "source": [
    "Below you can add code cells and improve on the network structure as you see fit (it still must be an MLP), train and test your network and explain why it works better.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML2021S-HW4-Practical.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
