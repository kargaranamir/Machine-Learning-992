{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "\n",
    "# ! pip install stopwords\n",
    "# ! pip install stop_words\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_BOW_SIZE = 1000\n",
    "DATASET_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(labels, predictions):\n",
    "    print(\"Report Classification: \\n\", classification_report(labels, predictions, target_names=['positive', 'negative']))\n",
    "    print(\"Matrix Confusion: \\n\", confusion_matrix(labels, predictions))\n",
    "    print(\"Accuracy: \\n\", accuracy_score(labels,predictions))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oh my god, it just doesn't get any worse than ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you're a layman interested in quantum theor...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's amazing that this no talent actor Chapa g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This must be one of the most overrated Spanish...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some critics have compared Chop Shop with the ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment sentiment\n",
       "0  Oh my god, it just doesn't get any worse than ...  negative\n",
       "1  If you're a layman interested in quantum theor...  negative\n",
       "2  It's amazing that this no talent actor Chapa g...  negative\n",
       "3  This must be one of the most overrated Spanish...  negative\n",
       "4  Some critics have compared Chop Shop with the ...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = pd.read_csv('dataset.csv')\n",
    "data_set = data_set[:DATASET_SIZE]\n",
    "data_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9983</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Elfriede Jelinek, not quite a household name y...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>5037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment sentiment\n",
       "count                                               10000     10000\n",
       "unique                                               9983         2\n",
       "top     Elfriede Jelinek, not quite a household name y...  negative\n",
       "freq                                                    2      5037"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "X = data_set['comment']\n",
    "Y = data_set['sentiment']\n",
    "\n",
    "\n",
    "# label binarization\n",
    "label_binarizer = LabelBinarizer()\n",
    "Y = label_binarizer.fit_transform(Y)\n",
    "Y = np.ravel(Y)\n",
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2: Without pre-processing\n",
    "- lowercase is False\n",
    "- Pattern: everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(lowercase = False, max_features=MAX_BOW_SIZE, token_pattern=\"[a-zA-Z0-9_'.]{1,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_X_train = count_vectorizer.fit_transform(X_train) #fit only over train data \n",
    "cv_X_test = count_vectorizer.transform(X_test) #apply not fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1: Without pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------SVM-------:\n",
      "Best parameters set found on development set:\n",
      "{'C': 10, 'kernel': 'rbf'}\n",
      "Report Classification: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.85      0.84      0.84      1010\n",
      "    negative       0.83      0.85      0.84       990\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n",
      "Matrix Confusion: \n",
      " [[844 166]\n",
      " [151 839]]\n",
      "Accuracy: \n",
      " 0.8415\n",
      "-------KNN-------:\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 21, 'weights': 'distance'}\n",
      "KNeighborsClassifier(n_neighbors=21, weights='distance')\n",
      "Report Classification: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.67      0.49      0.57      1010\n",
      "    negative       0.59      0.75      0.66       990\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.63      0.62      0.61      2000\n",
      "weighted avg       0.63      0.62      0.61      2000\n",
      "\n",
      "Matrix Confusion: \n",
      " [[498 512]\n",
      " [248 742]]\n",
      "Accuracy: \n",
      " 0.62\n",
      "-------LR-------:\n",
      "Best parameters set found on development set:\n",
      "{'C': 1, 'penalty': 'l2'}\n",
      "LogisticRegression(C=1)\n",
      "Report Classification: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.84      0.83      0.84      1010\n",
      "    negative       0.83      0.84      0.84       990\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n",
      "Matrix Confusion: \n",
      " [[837 173]\n",
      " [155 835]]\n",
      "Accuracy: \n",
      " 0.836\n"
     ]
    }
   ],
   "source": [
    "#### svm \n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'C': [1, 10]}]\n",
    "\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, scoring ='f1')\n",
    "clf.fit(cv_X_train, Y_train)\n",
    "\n",
    "print(\"-------SVM-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "analysis(Y_test, Y_test_pred)\n",
    "\n",
    "#### knn\n",
    "\n",
    "k_range = list(range(1,31))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(knn, param_grid, scoring ='f1')\n",
    "clf.fit(cv_X_train,Y_train)\n",
    "\n",
    "print(\"-------KNN-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print (clf.best_params_)\n",
    "print (clf.best_estimator_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "analysis(Y_test, Y_test_pred)\n",
    "\n",
    "#### logistic regression\n",
    "\n",
    "grid_values = {'penalty': ['l2'], 'C': [1,10]}\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid=grid_values, scoring = 'f1')\n",
    "\n",
    "clf.fit(cv_X_train,Y_train)\n",
    "\n",
    "print(\"-------LR-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print (clf.best_params_)\n",
    "print (clf.best_estimator_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "analysis(Y_test, Y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2: Elementry pre-processing\n",
    "- lowercase is True\n",
    "- Pattern: just words with lenght>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(lowercase=True, max_features=MAX_BOW_SIZE, token_pattern=\"[a-zA-Z_]{2,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_X_train = count_vectorizer.fit_transform(X_train) #fit only over train data \n",
    "cv_X_test = count_vectorizer.transform(X_test) #apply not fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1: Elementry pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------SVM-------:\n",
      "Best parameters set found on development set:\n",
      "{'C': 10, 'kernel': 'rbf'}\n",
      "Report Classification: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.84      0.85      0.85      1010\n",
      "    negative       0.85      0.84      0.84       990\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.85      0.85      0.85      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n",
      "Matrix Confusion: \n",
      " [[863 147]\n",
      " [160 830]]\n",
      "Accuracy: \n",
      " 0.8465\n",
      "-------KNN-------:\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 28, 'weights': 'distance'}\n",
      "KNeighborsClassifier(n_neighbors=28, weights='distance')\n",
      "Report Classification: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.71      0.49      0.58      1010\n",
      "    negative       0.61      0.80      0.69       990\n",
      "\n",
      "    accuracy                           0.65      2000\n",
      "   macro avg       0.66      0.65      0.64      2000\n",
      "weighted avg       0.66      0.65      0.64      2000\n",
      "\n",
      "Matrix Confusion: \n",
      " [[499 511]\n",
      " [199 791]]\n",
      "Accuracy: \n",
      " 0.645\n",
      "-------LR-------:\n",
      "Best parameters set found on development set:\n",
      "{'C': 1, 'penalty': 'l2'}\n",
      "LogisticRegression(C=1)\n",
      "Report Classification: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.83      0.82      0.83      1010\n",
      "    negative       0.82      0.83      0.83       990\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.83      0.83      0.83      2000\n",
      "weighted avg       0.83      0.83      0.83      2000\n",
      "\n",
      "Matrix Confusion: \n",
      " [[832 178]\n",
      " [169 821]]\n",
      "Accuracy: \n",
      " 0.8265\n"
     ]
    }
   ],
   "source": [
    "#### svm \n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'C': [1, 10]}]\n",
    "\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, scoring ='f1')\n",
    "clf.fit(cv_X_train, Y_train)\n",
    "\n",
    "print(\"-------SVM-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "analysis(Y_test, Y_test_pred)\n",
    "\n",
    "#### knn\n",
    "\n",
    "k_range = list(range(1,31))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(knn, param_grid, scoring ='f1')\n",
    "clf.fit(cv_X_train,Y_train)\n",
    "\n",
    "print(\"-------KNN-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print (clf.best_params_)\n",
    "print (clf.best_estimator_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "analysis(Y_test, Y_test_pred)\n",
    "\n",
    "#### logistic regression\n",
    "\n",
    "grid_values = {'penalty': ['l2'], 'C': [1,10]}\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid=grid_values, scoring = 'f1')\n",
    "\n",
    "clf.fit(cv_X_train,Y_train)\n",
    "\n",
    "print(\"-------LR-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print (clf.best_params_)\n",
    "print (clf.best_estimator_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "analysis(Y_test, Y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2: Adcanced pre-processing\n",
    "- lowercase is True\n",
    "- Pattern just words with lenght>1\n",
    "- lemmatize\n",
    "- stopwrods\n",
    "- abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(get_stop_words('en'))\n",
    "nltk_words = list(stopwords.words('english'))\n",
    "stop_words.extend(nltk_words)\n",
    "\n",
    "def lemmatize(text):\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    \n",
    "    tagged_words = pos_tag(text)\n",
    "    for word in tagged_words:\n",
    "        if 'v' in word[1].lower():\n",
    "            lemma = lmtzr.lemmatize(word[0], pos='v')\n",
    "        else:\n",
    "            lemma = lmtzr.lemmatize(word[0], pos='n')\n",
    "        if list_pos == 0:\n",
    "            cleaned_str = lemma\n",
    "        else:\n",
    "            cleaned_str = cleaned_str + ' ' + lemma\n",
    "        list_pos += 1\n",
    "    return cleaned_str\n",
    "\n",
    "def clean(text):\n",
    "    text = str(text).lower() #lowercase\n",
    "    text = re.sub(r'\\bid\\b', 'i would', text) #start abbreviation\n",
    "    text = re.sub(r'\\bive\\b', 'i have', text)\n",
    "    text = re.sub(r'\\bim\\b', 'i am', text)\n",
    "    text = re.sub(r'\\bcant\\b', 'can not', text)\n",
    "    text = re.sub(r'\\bdont\\b', 'do not', text)\n",
    "    text = re.sub(r'\\bwont\\b', 'will not', text)\n",
    "    text = re.sub(r'\\bthats\\b', 'that is', text) #end abbreviation\n",
    "    text = re.sub('[0-9]+', '', text) # delete numbers\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text) #remove non-ascii\n",
    "    text = re.sub('[<>{}=~.,،:\\\\!?\\\\-()\\\\[\\\\]#/@\"]+|[_x000D_]+|\\u200c+|[\\r\\n]', ' ', text) #remove punctuations\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    text = lemmatize(word_list)\n",
    "    word_list = text.split()\n",
    "    word_list = list(filter(lambda word: word not in stop_words, word_list)) # delete stopwords\n",
    "    word_list = [w for w in word_list if len(w)>1] # delete len = 1\n",
    "    return word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(tokenizer=lambda text: clean(text), max_features=MAX_BOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_X_train = count_vectorizer.fit_transform(X_train) #fit only over train data \n",
    "cv_X_test = count_vectorizer.transform(X_test) #apply not fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1: Advanced pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------SVM-------:\n",
      "Best parameters set found on development set:\n",
      "{'C': 1, 'kernel': 'rbf'}\n",
      "Report Classification: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.86      0.83      0.84      1010\n",
      "    negative       0.83      0.87      0.85       990\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.85      0.85      0.85      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n",
      "Matrix Confusion: \n",
      " [[835 175]\n",
      " [133 857]]\n",
      "Accuracy: \n",
      " 0.846\n",
      "-------KNN-------:\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 28, 'weights': 'distance'}\n",
      "KNeighborsClassifier(n_neighbors=28, weights='distance')\n",
      "Report Classification: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.68      0.61      0.64      1010\n",
      "    negative       0.64      0.71      0.67       990\n",
      "\n",
      "    accuracy                           0.66      2000\n",
      "   macro avg       0.66      0.66      0.66      2000\n",
      "weighted avg       0.66      0.66      0.66      2000\n",
      "\n",
      "Matrix Confusion: \n",
      " [[613 397]\n",
      " [291 699]]\n",
      "Accuracy: \n",
      " 0.656\n",
      "-------LR-------:\n",
      "Best parameters set found on development set:\n",
      "{'C': 1, 'penalty': 'l2'}\n",
      "LogisticRegression(C=1)\n",
      "Report Classification: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.83      0.83      0.83      1010\n",
      "    negative       0.83      0.83      0.83       990\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.83      0.83      0.83      2000\n",
      "weighted avg       0.83      0.83      0.83      2000\n",
      "\n",
      "Matrix Confusion: \n",
      " [[841 169]\n",
      " [167 823]]\n",
      "Accuracy: \n",
      " 0.832\n"
     ]
    }
   ],
   "source": [
    "#### svm \n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'C': [1, 10]}]\n",
    "\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, scoring ='f1')\n",
    "clf.fit(cv_X_train, Y_train)\n",
    "\n",
    "print(\"-------SVM-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "analysis(Y_test, Y_test_pred)\n",
    "\n",
    "#### knn\n",
    "\n",
    "k_range = list(range(1,31))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(knn, param_grid, scoring ='f1')\n",
    "clf.fit(cv_X_train,Y_train)\n",
    "\n",
    "print(\"-------KNN-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print (clf.best_params_)\n",
    "print (clf.best_estimator_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "analysis(Y_test, Y_test_pred)\n",
    "\n",
    "#### logistic regression\n",
    "\n",
    "grid_values = {'penalty': ['l2'], 'C': [1,10]}\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid=grid_values, scoring = 'f1')\n",
    "\n",
    "clf.fit(cv_X_train,Y_train)\n",
    "\n",
    "print(\"-------LR-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print (clf.best_params_)\n",
    "print (clf.best_estimator_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "analysis(Y_test, Y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
