{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "\n",
    "# ! pip install stopwords\n",
    "# ! pip install stop_words\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 100\n",
    "MAX_BOW_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oh my god, it just doesn't get any worse than ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you're a layman interested in quantum theor...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's amazing that this no talent actor Chapa g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This must be one of the most overrated Spanish...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some critics have compared Chop Shop with the ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment sentiment\n",
       "0  Oh my god, it just doesn't get any worse than ...  negative\n",
       "1  If you're a layman interested in quantum theor...  negative\n",
       "2  It's amazing that this no talent actor Chapa g...  negative\n",
       "3  This must be one of the most overrated Spanish...  negative\n",
       "4  Some critics have compared Chop Shop with the ...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = pd.read_csv('dataset.csv')\n",
    "data_set = data_set[:DATASET_SIZE] \n",
    "data_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>One of the best silent dramas I've seen. As da...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment sentiment\n",
       "count                                                 100       100\n",
       "unique                                                100         2\n",
       "top     One of the best silent dramas I've seen. As da...  positive\n",
       "freq                                                    1        50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_set['comment']\n",
    "Y = data_set['sentiment']\n",
    "\n",
    "\n",
    "# label binarization\n",
    "label_binarizer = LabelBinarizer()\n",
    "Y = label_binarizer.fit_transform(Y)\n",
    "Y = np.ravel(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2: Without pre-processing\n",
    "- lowercase is False\n",
    "- Pattern: everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(lowercase = False, max_features=MAX_BOW_SIZE, token_pattern=\"[a-zA-Z0-9_'.]{1,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_X_train = count_vectorizer.fit_transform(X_train) #fit only over train data \n",
    "cv_X_test = count_vectorizer.transform(X_test) #apply not fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1: Without pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------SVM-------:\n",
      "Best parameters set found on development set:\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.33      0.36        12\n",
      "           1       0.20      0.25      0.22         8\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.30      0.29      0.29        20\n",
      "weighted avg       0.32      0.30      0.31        20\n",
      "\n",
      "-------KNN-------:\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 9, 'weights': 'distance'}\n",
      "KNeighborsClassifier(n_neighbors=9, weights='distance')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.42      0.50        12\n",
      "           1       0.42      0.62      0.50         8\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.52      0.52      0.50        20\n",
      "weighted avg       0.54      0.50      0.50        20\n",
      "\n",
      "-------LR-------:\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.01, 'penalty': 'l2'}\n",
      "LogisticRegression(C=0.01)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.42      0.48        12\n",
      "           1       0.36      0.50      0.42         8\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.46      0.46      0.45        20\n",
      "weighted avg       0.48      0.45      0.45        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### svm \n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv = 4, scoring='accuracy')\n",
    "clf.fit(cv_X_train, Y_train)\n",
    "\n",
    "print(\"-------SVM-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "print(classification_report(Y_test, Y_test_pred))\n",
    "\n",
    "#### knn\n",
    "\n",
    "k_range = list(range(1,10))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(knn, param_grid, cv = 4, scoring = 'accuracy')\n",
    "clf.fit(cv_X_train,Y_train)\n",
    "\n",
    "print(\"-------KNN-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print (clf.best_params_)\n",
    "print (clf.best_estimator_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "print(classification_report(Y_test, Y_test_pred))\n",
    "\n",
    "#### logistic regression\n",
    "\n",
    "grid_values = {'penalty': ['l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]}\n",
    "clf = GridSearchCV(LogisticRegression(), cv = 4, param_grid=grid_values, scoring = 'accuracy')\n",
    "\n",
    "clf.fit(cv_X_train,Y_train)\n",
    "\n",
    "print(\"-------LR-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print (clf.best_params_)\n",
    "print (clf.best_estimator_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "print(classification_report(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2: Elementry pre-processing\n",
    "- lowercase is True\n",
    "- Pattern: just words with lenght>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(lowercase=True, max_features=MAX_BOW_SIZE, token_pattern=\"[a-zA-Z_]{2,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_X_train = count_vectorizer.fit_transform(X_train) #fit only over train data \n",
    "cv_X_test = count_vectorizer.transform(X_test) #apply not fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1: Elementry pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------SVM-------:\n",
      "Best parameters set found on development set:\n",
      "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50        12\n",
      "           1       0.25      0.25      0.25         8\n",
      "\n",
      "    accuracy                           0.40        20\n",
      "   macro avg       0.38      0.38      0.38        20\n",
      "weighted avg       0.40      0.40      0.40        20\n",
      "\n",
      "-------KNN-------:\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 8, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(n_neighbors=8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40        12\n",
      "           1       0.33      0.50      0.40         8\n",
      "\n",
      "    accuracy                           0.40        20\n",
      "   macro avg       0.42      0.42      0.40        20\n",
      "weighted avg       0.43      0.40      0.40        20\n",
      "\n",
      "-------LR-------:\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.001, 'penalty': 'l2'}\n",
      "LogisticRegression(C=0.001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.25      0.35        12\n",
      "           1       0.40      0.75      0.52         8\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.50      0.50      0.44        20\n",
      "weighted avg       0.52      0.45      0.42        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### svm \n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv = 4, scoring='accuracy')\n",
    "clf.fit(cv_X_train, Y_train)\n",
    "\n",
    "print(\"-------SVM-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "print(classification_report(Y_test, Y_test_pred))\n",
    "\n",
    "#### knn\n",
    "\n",
    "k_range = list(range(1,10))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(knn, param_grid, cv = 4, scoring = 'accuracy')\n",
    "clf.fit(cv_X_train,Y_train)\n",
    "\n",
    "print(\"-------KNN-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print (clf.best_params_)\n",
    "print (clf.best_estimator_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "print(classification_report(Y_test, Y_test_pred))\n",
    "\n",
    "#### logistic regression\n",
    "\n",
    "grid_values = {'penalty': ['l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]}\n",
    "clf = GridSearchCV(LogisticRegression(), cv = 4, param_grid=grid_values, scoring = 'accuracy')\n",
    "\n",
    "clf.fit(cv_X_train,Y_train)\n",
    "\n",
    "print(\"-------LR-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print (clf.best_params_)\n",
    "print (clf.best_estimator_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "print(classification_report(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2: Adcanced pre-processing\n",
    "- lowercase is True\n",
    "- Pattern just words with lenght>1\n",
    "- lemmatize\n",
    "- stopwrods\n",
    "- abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(get_stop_words('en'))\n",
    "nltk_words = list(stopwords.words('english'))\n",
    "stop_words.extend(nltk_words)\n",
    "\n",
    "def lemmatize(text):\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    \n",
    "    tagged_words = pos_tag(text)\n",
    "    for word in tagged_words:\n",
    "        if 'v' in word[1].lower():\n",
    "            lemma = lmtzr.lemmatize(word[0], pos='v')\n",
    "        else:\n",
    "            lemma = lmtzr.lemmatize(word[0], pos='n')\n",
    "        if list_pos == 0:\n",
    "            cleaned_str = lemma\n",
    "        else:\n",
    "            cleaned_str = cleaned_str + ' ' + lemma\n",
    "        list_pos += 1\n",
    "    return cleaned_str\n",
    "\n",
    "def clean(text):\n",
    "    text = str(text).lower() #lowercase\n",
    "    text = re.sub(r'\\bid\\b', 'i would', text) #start abbreviation\n",
    "    text = re.sub(r'\\bive\\b', 'i have', text)\n",
    "    text = re.sub(r'\\bim\\b', 'i am', text)\n",
    "    text = re.sub(r'\\bcant\\b', 'can not', text)\n",
    "    text = re.sub(r'\\bdont\\b', 'do not', text)\n",
    "    text = re.sub(r'\\bwont\\b', 'will not', text)\n",
    "    text = re.sub(r'\\bthats\\b', 'that is', text) #end abbreviation\n",
    "    text = re.sub('[0-9]+', '', text) # delete numbers\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text) #remove non-ascii\n",
    "    text = re.sub('[<>{}=~.,ØŒ:\\\\!?\\\\-()\\\\[\\\\]#/@\"]+|[_x000D_]+|\\u200c+|[\\r\\n]', ' ', text) #remove punctuations\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    text = lemmatize(word_list)\n",
    "    word_list = text.split()\n",
    "    word_list = list(filter(lambda word: word not in stop_words, word_list)) # delete stopwords\n",
    "    word_list = [w for w in word_list if len(w)>1] # delete len = 1\n",
    "    return word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(tokenizer=lambda text: clean(text), max_features=MAX_BOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_X_train = count_vectorizer.fit_transform(X_train) #fit only over train data \n",
    "cv_X_test = count_vectorizer.transform(X_test) #apply not fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1: Advanced pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------SVM-------:\n",
      "Best parameters set found on development set:\n",
      "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.15        12\n",
      "           1       0.42      1.00      0.59         8\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.71      0.54      0.37        20\n",
      "weighted avg       0.77      0.45      0.33        20\n",
      "\n",
      "-------KNN-------:\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 2, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(n_neighbors=2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.58      0.56        12\n",
      "           1       0.29      0.25      0.27         8\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.41      0.42      0.41        20\n",
      "weighted avg       0.44      0.45      0.44        20\n",
      "\n",
      "-------LR-------:\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.001, 'penalty': 'l2'}\n",
      "LogisticRegression(C=0.001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.25      0.35        12\n",
      "           1       0.40      0.75      0.52         8\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.50      0.50      0.44        20\n",
      "weighted avg       0.52      0.45      0.42        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### svm \n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv = 4, scoring='accuracy')\n",
    "clf.fit(cv_X_train, Y_train)\n",
    "\n",
    "print(\"-------SVM-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "print(classification_report(Y_test, Y_test_pred))\n",
    "\n",
    "#### knn\n",
    "\n",
    "k_range = list(range(1,10))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(knn, param_grid, cv = 4, scoring = 'accuracy')\n",
    "clf.fit(cv_X_train,Y_train)\n",
    "\n",
    "print(\"-------KNN-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print (clf.best_params_)\n",
    "print (clf.best_estimator_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "print(classification_report(Y_test, Y_test_pred))\n",
    "\n",
    "#### logistic regression\n",
    "\n",
    "grid_values = {'penalty': ['l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]}\n",
    "clf = GridSearchCV(LogisticRegression(), cv = 4, param_grid=grid_values, scoring = 'accuracy')\n",
    "\n",
    "clf.fit(cv_X_train,Y_train)\n",
    "\n",
    "print(\"-------LR-------:\")\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print (clf.best_params_)\n",
    "print (clf.best_estimator_)\n",
    "Y_test_pred = clf.predict(cv_X_test)\n",
    "print(classification_report(Y_test, Y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
